{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "from keras import optimizers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(words):\n",
    "    bigrams = []\n",
    "    for b in words:\n",
    "        bigrams.append([b[i:i+2] for i in range(len(b)-1)])\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/dataset.csv')\n",
    "# print('data shape: {}'.format(df.shape))\n",
    "\n",
    "X = df['NAME']\n",
    "y = df['NATIONALITY']\n",
    "\n",
    "classes = y.unique()\n",
    "# print(classes)\n",
    "num_classes = len(y.unique())\n",
    "\n",
    "# print('number of classes: {}'.format(num_classes))\n",
    "\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "# print('train data shape X, y: {},{}'.format(X_train_df.shape, y_train_df.shape))\n",
    "# print('test data shape X, y: {},{}'.format(X_test_df.shape, y_test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', \n",
    "          lower=False, char_level=True, oov_token=None)\n",
    "\n",
    "y_tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', \n",
    "          lower=True, char_level=False, oov_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_df.values.astype(str) # Otherwise, there's an error when calling 'fit_on_texts' >> AttributeError: 'int' object has no attribute 'lower'\n",
    "X_test = X_test_df.values.astype(str) # Otherwise, there's an error when calling 'fit_on_texts' >> AttributeError: 'int' object has no attribute 'lower'\n",
    "\n",
    "# X_train = bigrams(X_train)\n",
    "\n",
    "X_tokenizer.fit_on_texts(X_train)\n",
    "X_train = X_tokenizer.texts_to_sequences(X_train)\n",
    "X_test = X_tokenizer.texts_to_sequences(X_test)\n",
    "# print(len(X_tokenizer.index_word))\n",
    "\n",
    "X_train = X_tokenizer.sequences_to_matrix(X_train, mode='tfidf')\n",
    "X_test = X_tokenizer.sequences_to_matrix(X_test, mode='tfidf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode from string labels to numerical labels \n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train_df.values.astype(str)) # error without astype(str)\n",
    "y_test = label_encoder.transform(y_test_df.values.astype(str))\n",
    "# print(encoder.classes_.shape)\n",
    "# encoder.inverse_transform(y_train)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# X_tokenizer.word_counts\n",
    "# print(len(X_tokenizer.word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700 train sequences\n",
      "1425 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (5700, 30)\n",
      "X_test shape: (1425, 30)\n",
      "Hyperparameters\n",
      "max_features = 54\n",
      "batch_size = 23\n",
      "maxlen = 30\n",
      "embedding_dims = 50\n",
      "epochs = 20\n"
     ]
    }
   ],
   "source": [
    "max_features = len(X_tokenizer.word_counts)\n",
    "# print('max_features = {}'.format(max_features))\n",
    "batch_size = 23\n",
    "maxlen = 30\n",
    "embedding_dims = 50\n",
    "epochs=20\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, padding=\"post\", maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, padding=\"post\", maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Hyperparameters')\n",
    "print('max_features = {}'.format(max_features))\n",
    "print('batch_size = {}'.format(batch_size))\n",
    "print('maxlen = {}'.format(maxlen))\n",
    "print('embedding_dims = {}'.format(embedding_dims))\n",
    "print('epochs = {}'.format(epochs))\n",
    "\n",
    "def train_model():\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features,\n",
    "                        embedding_dims,\n",
    "                        input_length=maxlen))\n",
    "    model.add(SimpleRNN(embedding_dims))\n",
    "\n",
    "#     model.add(LSTM(maxlen))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    print('Train...')\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_test, y_test),\n",
    "                verbose=0\n",
    "             )\n",
    "    score, acc = model.evaluate(X_test, y_test,\n",
    "                                batch_size=batch_size,\n",
    "                               verbose=1)\n",
    "\n",
    "\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, 30, 50)            2700      \n",
      "_________________________________________________________________\n",
      "simple_rnn_28 (SimpleRNN)    (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 7,903\n",
      "Trainable params: 7,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train...\n",
      "1425/1425 [==============================] - 0s 72us/step\n",
      "Test score: 0.97146679050044\n",
      "Test accuracy: 0.480701744556427\n",
      "CPU times: user 1min 1s, sys: 16.5 s, total: 1min 17s\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(X_test)\n",
    "\n",
    "def plot_model(filename='model_plot_0.png'):\n",
    "    plot_model(model, to_file=filename, show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "def plot_hist():\n",
    "    colors = ['#E69F00', '#56B4E9', '#F0E442']    \n",
    "    plt.hist(results.transpose(), normed=False)\n",
    "    \n",
    "def plot_loss():\n",
    "    plt.plot(history.history['loss'])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
