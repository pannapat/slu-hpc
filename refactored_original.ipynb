{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "from keras import optimizers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(words):\n",
    "    bigrams = []\n",
    "    for b in words:\n",
    "        bigrams.append([b[i:i+2] for i in range(len(b)-1)])\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/dataset.csv')\n",
    "# print('data shape: {}'.format(df.shape))\n",
    "\n",
    "X = df['NAME']\n",
    "y = df['NATIONALITY']\n",
    "\n",
    "classes = y.unique()\n",
    "# print(classes)\n",
    "num_classes = len(y.unique())\n",
    "\n",
    "# print('number of classes: {}'.format(num_classes))\n",
    "\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "# print('train data shape X, y: {},{}'.format(X_train_df.shape, y_train_df.shape))\n",
    "# print('test data shape X, y: {},{}'.format(X_test_df.shape, y_test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', \n",
    "          lower=False, char_level=True, oov_token=None)\n",
    "\n",
    "y_tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', \n",
    "          lower=True, char_level=False, oov_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_df.values.astype(str) # Otherwise, there's an error when calling 'fit_on_texts' >> AttributeError: 'int' object has no attribute 'lower'\n",
    "X_test = X_test_df.values.astype(str) # Otherwise, there's an error when calling 'fit_on_texts' >> AttributeError: 'int' object has no attribute 'lower'\n",
    "\n",
    "# X_train = bigrams(X_train)\n",
    "\n",
    "X_tokenizer.fit_on_texts(X_train)\n",
    "X_train = X_tokenizer.texts_to_sequences(X_train)\n",
    "X_test = X_tokenizer.texts_to_sequences(X_test)\n",
    "# print(len(X_tokenizer.index_word))\n",
    "\n",
    "X_train = X_tokenizer.sequences_to_matrix(X_train, mode='tfidf')\n",
    "X_test = X_tokenizer.sequences_to_matrix(X_test, mode='tfidf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode from string labels to numerical labels \n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train_df.values.astype(str)) # error without astype(str)\n",
    "y_test = label_encoder.transform(y_test_df.values.astype(str))\n",
    "# print(encoder.classes_.shape)\n",
    "# encoder.inverse_transform(y_train)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# X_tokenizer.word_counts\n",
    "# print(len(X_tokenizer.word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5700 train sequences\n1425 test sequences\nPad sequences (samples x time)\nX_train shape: (5700, 30)\nX_test shape: (1425, 30)\nHyperparameters\nmax_features = 54\nbatch_size = 23\nmaxlen = 30\nembedding_dims = 50\nepochs = 20\n"
    }
   ],
   "source": [
    "max_features = len(X_tokenizer.word_counts)\n",
    "# print('max_features = {}'.format(max_features))\n",
    "batch_size = 23\n",
    "maxlen = 30\n",
    "embedding_dims = 50\n",
    "epochs=20\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, padding=\"post\", maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, padding=\"post\", maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Hyperparameters')\n",
    "print('max_features = {}'.format(max_features))\n",
    "print('batch_size = {}'.format(batch_size))\n",
    "print('maxlen = {}'.format(maxlen))\n",
    "print('embedding_dims = {}'.format(embedding_dims))\n",
    "print('epochs = {}'.format(epochs))\n",
    "\n",
    "def train_model():\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features,\n",
    "                        embedding_dims,\n",
    "                        input_length=maxlen))\n",
    "    model.add(SimpleRNN(embedding_dims))\n",
    "\n",
    "#     model.add(LSTM(maxlen))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    print('Train...')\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_test, y_test),\n",
    "                verbose=0\n",
    "             )\n",
    "    score, acc = model.evaluate(X_test, y_test,\n",
    "                                batch_size=batch_size,\n",
    "                               verbose=1)\n",
    "\n",
    "\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Build model...\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 30, 50)            2700      \n_________________________________________________________________\nsimple_rnn_1 (SimpleRNN)     (None, 50)                5050      \n_________________________________________________________________\ndense_1 (Dense)              (None, 3)                 153       \n=================================================================\nTotal params: 7,903\nTrainable params: 7,903\nNon-trainable params: 0\n_________________________________________________________________\nNone\nTrain...\n1425/1425 [==============================] - 0s 92us/step\nTest score: 0.9622427932003088\nTest accuracy: 0.4582456052303314\nCPU times: user 1min, sys: 15.8 s, total: 1min 16s\nWall time: 31.3 s\n"
    }
   ],
   "source": [
    "%time _ = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2aa3b14b4388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_plot_0.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# results = model.predict(X_test)\n",
    "\n",
    "# def plot_model(filename='model_plot_0.png'):\n",
    "#     plot_model(model, to_file=filename, show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "# def plot_hist():\n",
    "#     colors = ['#E69F00', '#56B4E9', '#F0E442']    \n",
    "#     plt.hist(results.transpose(), normed=False)\n",
    "    \n",
    "# def plot_loss():\n",
    "#     plt.plot(history.history['loss'])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}