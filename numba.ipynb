{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "from keras import optimizers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import time\n",
    "from numba import njit, jit, vectorize\n",
    "from numba import prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(words):\n",
    "    bigrams = []\n",
    "    for b in words:\n",
    "        bigrams.append([b[i:i+2] for i in range(len(b)-1)])\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/dataset.csv')\n",
    "# print('data shape: {}'.format(df.shape))\n",
    "\n",
    "X = df['NAME']\n",
    "y = df['NATIONALITY']\n",
    "\n",
    "classes = y.unique()\n",
    "# print(classes)\n",
    "num_classes = len(y.unique())\n",
    "\n",
    "# print('number of classes: {}'.format(num_classes))\n",
    "\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "# print('train data shape X, y: {},{}'.format(X_train_df.shape, y_train_df.shape))\n",
    "# print('test data shape X, y: {},{}'.format(X_test_df.shape, y_test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', \n",
    "          lower=False, char_level=True, oov_token=None)\n",
    "\n",
    "y_tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', \n",
    "          lower=True, char_level=False, oov_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_df.values.astype(str) # Otherwise, there's an error when calling 'fit_on_texts' >> AttributeError: 'int' object has no attribute 'lower'\n",
    "X_test = X_test_df.values.astype(str) # Otherwise, there's an error when calling 'fit_on_texts' >> AttributeError: 'int' object has no attribute 'lower'\n",
    "\n",
    "# X_train = bigrams(X_train)\n",
    "\n",
    "X_tokenizer.fit_on_texts(X_train)\n",
    "X_train = X_tokenizer.texts_to_sequences(X_train)\n",
    "X_test = X_tokenizer.texts_to_sequences(X_test)\n",
    "# print(len(X_tokenizer.index_word))\n",
    "\n",
    "X_train = X_tokenizer.sequences_to_matrix(X_train, mode='tfidf')\n",
    "X_test = X_tokenizer.sequences_to_matrix(X_test, mode='tfidf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode from string labels to numerical labels \n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train_df.values.astype(str)) # error without astype(str)\n",
    "y_test = label_encoder.transform(y_test_df.values.astype(str))\n",
    "# print(encoder.classes_.shape)\n",
    "# encoder.inverse_transform(y_train)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# X_tokenizer.word_counts\n",
    "# print(len(X_tokenizer.word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700 train sequences\n",
      "1425 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (5700, 30)\n",
      "X_test shape: (1425, 30)\n",
      "Hyperparameters\n",
      "max_features = 54\n",
      "batch_size = 23\n",
      "maxlen = 30\n",
      "embedding_dims = 50\n",
      "epochs = 20\n"
     ]
    }
   ],
   "source": [
    "max_features = len(X_tokenizer.word_counts)\n",
    "# print('max_features = {}'.format(max_features))\n",
    "batch_size = 23\n",
    "maxlen = 30\n",
    "embedding_dims = 50\n",
    "epochs=20\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, padding=\"post\", maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, padding=\"post\", maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Hyperparameters')\n",
    "print('max_features = {}'.format(max_features))\n",
    "print('batch_size = {}'.format(batch_size))\n",
    "print('maxlen = {}'.format(maxlen))\n",
    "print('embedding_dims = {}'.format(embedding_dims))\n",
    "print('epochs = {}'.format(epochs))\n",
    "\n",
    "def train_model():\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features,\n",
    "                        embedding_dims,\n",
    "                        input_length=maxlen))\n",
    "    model.add(SimpleRNN(embedding_dims))\n",
    "\n",
    "#     model.add(LSTM(maxlen))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    print('Train...')\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_test, y_test),\n",
    "                verbose=0\n",
    "             )\n",
    "    score, acc = model.evaluate(X_test, y_test,\n",
    "                                batch_size=batch_size,\n",
    "                               verbose=1)\n",
    "\n",
    "\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 50)            2700      \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 7,903\n",
      "Trainable params: 7,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goople/workspace/slu/spring2020/hpc/ml-project/env/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425/1425 [==============================] - 0s 79us/step\n",
      "Test score: 0.9729887019960504\n",
      "Test accuracy: 0.4863157868385315\n",
      "CPU times: user 1min 1s, sys: 16.7 s, total: 1min 18s\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-92c7b4529182>:24: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"train_model\" failed type inference due to: Untyped global name 'Sequential': cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"<ipython-input-8-92c7b4529182>\", line 26:\n",
      "def train_model():\n",
      "    <source elided>\n",
      "    print('Build model...')\n",
      "    model = Sequential()\n",
      "    ^\n",
      "\n",
      "  def train_model():\n",
      "/Users/goople/workspace/slu/spring2020/hpc/ml-project/env/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"train_model\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-8-92c7b4529182>\", line 24:\n",
      "\n",
      "def train_model():\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/goople/workspace/slu/spring2020/hpc/ml-project/env/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-8-92c7b4529182>\", line 24:\n",
      "\n",
      "def train_model():\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "<ipython-input-8-92c7b4529182>:24: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.\n",
      "  def train_model():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 50)            2700      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 7,903\n",
      "Trainable params: 7,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train...\n",
      "1425/1425 [==============================] - 0s 77us/step\n",
      "Test score: 0.9599297831769575\n",
      "Test accuracy: 0.48561403155326843\n",
      "CPU times: user 1min 1s, sys: 16.5 s, total: 1min 18s\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "jitted_train_model = jit(nogil=True)(train_model)\n",
    "%time _ = jitted_train_model();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 30, 50)            2700      \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 7,903\n",
      "Trainable params: 7,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train...\n",
      "1425/1425 [==============================] - 0s 75us/step\n",
      "Test score: 0.9643213196386371\n",
      "Test accuracy: 0.4863157868385315\n",
      "CPU times: user 1min 2s, sys: 17 s, total: 1min 19s\n",
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = jitted_train_model();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-231415e0a5d3>:3: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"simulate\" failed type inference due to: Untyped global name 'train_model': cannot determine Numba type of <class 'function'>\n",
      "\n",
      "File \"<ipython-input-14-231415e0a5d3>\", line 6:\n",
      "def simulate():\n",
      "    <source elided>\n",
      "    for _ in prange(3):\n",
      "        train_model()\n",
      "        ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "<ipython-input-14-231415e0a5d3>:3: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"simulate\" failed type inference due to: cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-14-231415e0a5d3>\", line 5:\n",
      "def simulate():\n",
      "    for _ in prange(3):\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/Users/goople/workspace/slu/spring2020/hpc/ml-project/env/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"simulate\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-14-231415e0a5d3>\", line 5:\n",
      "def simulate():\n",
      "    for _ in prange(3):\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/goople/workspace/slu/spring2020/hpc/ml-project/env/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-14-231415e0a5d3>\", line 5:\n",
      "def simulate():\n",
      "    for _ in prange(3):\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "<ipython-input-14-231415e0a5d3>:3: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"simulate\" failed type inference due to: Untyped global name 'train_model': cannot determine Numba type of <class 'function'>\n",
      "\n",
      "File \"<ipython-input-14-231415e0a5d3>\", line 6:\n",
      "def simulate():\n",
      "    <source elided>\n",
      "    for _ in prange(3):\n",
      "        train_model()\n",
      "        ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/Users/goople/workspace/slu/spring2020/hpc/ml-project/env/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"simulate\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-14-231415e0a5d3>\", line 5:\n",
      "def simulate():\n",
      "    for _ in prange(3):\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/goople/workspace/slu/spring2020/hpc/ml-project/env/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-14-231415e0a5d3>\", line 5:\n",
      "def simulate():\n",
      "    for _ in prange(3):\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 30, 50)            2700      \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 7,903\n",
      "Trainable params: 7,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goople/workspace/slu/spring2020/hpc/ml-project/env/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425/1425 [==============================] - 0s 74us/step\n",
      "Test score: 0.9934027745849208\n",
      "Test accuracy: 0.43929824233055115\n",
      "Build model...\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 30, 50)            2700      \n",
      "_________________________________________________________________\n",
      "simple_rnn_7 (SimpleRNN)     (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 7,903\n",
      "Trainable params: 7,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train...\n",
      "1425/1425 [==============================] - 0s 63us/step\n",
      "Test score: 0.9698440140590333\n",
      "Test accuracy: 0.48491227626800537\n",
      "Build model...\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 30, 50)            2700      \n",
      "_________________________________________________________________\n",
      "simple_rnn_8 (SimpleRNN)     (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 7,903\n",
      "Trainable params: 7,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train...\n",
      "1425/1425 [==============================] - 0s 65us/step\n",
      "Test score: 0.9627202249828137\n",
      "Test accuracy: 0.48561403155326843\n",
      "CPU times: user 2min 52s, sys: 46.4 s, total: 3min 39s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "from numba import prange\n",
    "\n",
    "@jit(parallel=True)\n",
    "def simulate():\n",
    "    for _ in prange(3):\n",
    "        train_model()\n",
    "\n",
    "%time simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
